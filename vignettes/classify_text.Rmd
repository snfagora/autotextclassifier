---
title: "classify_text"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{classify_text}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(autotextclassifier)
library(here)
library(recipes)
library(zeallot)
```

# Import data 

```{r}
load(file = here("inst/extdata/sample_data.rda"))
```

# Data munging 

Don't forget to make sure that the type of the outcome variable is factor.

```{r eval = FALSE}
names(sample_data) <- c("category", "org_name", "ein", "text")

sample_data$category <- as.factor(sample_data$category)
```

# Apply basic recipe 

The following information is provided by the `rec` object.

> Training data contained 232 data points and no missing data.

> Operations:

> Tokenization for text [trained]
Stop word removal for text [trained]
Text filtering for text [trained]
Term frequency-inverse document frequency with text [trained]

```{r eval = FALSE}
rec_obj <- recipe(category ~ text, data = sample_data)

rec <- apply_basic_recipe(rec_obj, text)
```

# Split data 

```{r eval = FALSE}
set.seed(1234)

data_obj <- split_using_srs(data = sample_data, category = category, rec = rec)

c(train_x_class, test_x_class, train_y_class, test_y_class) %<-% data_obj
```

# Create tuning parameters 

```{r}
c(lasso_spec, rand_spec, xg_spec) %<-% create_tunes()
```

# Create search spaces 

# Create workflows 

# Create 10-fold cross-validation samples 

```{r}
class_folds <- create_cv_folds(train_x_class, train_y_class, category)
```

# Select best model 

```{r}
best_model <- select_best(lasso_wf, rand_wf, xg_wf,
                        class_folds, lasso_grid, rand_grid, xg_grid)
```



