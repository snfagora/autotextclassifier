---
title: "classify_text"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{classify_text}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(autotextclassifier)
devtools::load_all() # Load updated functions 

library(parallel)
library(doParallel)
library(here)
library(patchwork)
library(recipes)
library(zeallot)
```

# Import data 

```{r}
load(file = here("inst/extdata/sample_data.rda"))
```

# Data munging 

Don't forget to make sure that the type of the outcome variable is factor.

```{r eval = FALSE}
names(sample_data) <- c("category", "org_name", "ein", "text")
sample_data$category <- as.factor(sample_data$category)
```

# Apply basic recipe 

The following information is provided by the `rec` object.

> Training data contained 232 data points and no missing data.

> Operations:

> Tokenization for text [trained]
Stop word removal for text [trained]
Text filtering for text [trained]
Term frequency-inverse document frequency with text [trained]

```{r eval = FALSE}
rec_obj <- recipe(category ~ text, data = sample_data)
rec <- apply_basic_recipe(rec_obj, text)
```

# Split data 

```{r eval = FALSE}
set.seed(1234)

data_obj <- split_using_srs(data = sample_data, category = category, rec = rec)

c(train_x_class, test_x_class, train_y_class, test_y_class) %<-% data_obj
```

# Create tuning parameters 

```{r}
c(lasso_spec, rand_spec, xg_spec) %<-% create_tunes()
```

# Create search spaces 

```{r eval = FALSE}
c(lasso_grid, rand_grid, xg_grid) %<-% create_search_spaces(train_x_class, category, lasso_sepc, rand_spec, xg_spec)
```

# Create workflows 

```{r eval = FALSE}
c(lasso_wf, rand_wf, xg_wf) %<-% create_workflows(lasso_spec, rand_spec, xg_spec, category)
```

# Create 10-fold cross-validation samples 

```{r eval = FALSE}
class_folds <- create_cv_folds(train_x_class, train_y_class, category)
```

# Select best model from each algorithm

This part is most time-consuming.

```{r eval = FALSE}
all_cores <- parallel::detectCores(logical = FALSE)

cl <- makeCluster(all_cores[1] - 1)

registerDoParallel(cl)
```

```{r eval = FALSE}
c(best_lasso, best_rand, best_xg) %<-% find_best_model(lasso_wf, rand_wf, xg_wf, class_folds, lasso_grid, rand_grid, xg_grid)
```

# Fit the best model from each algorithm to the data 

```{r eval = FALSE}
c(lasso_fit, rand_fit, xg_fit) %<-% fit_best_models(lasso_wf, best_lasso, rand_wf, best_rand, xg_wf, best_xg, train_x_class, train_y_class, category)
```

# Evaluate the model using visualization

```{r eval = FALSE}
viz_class_eval(lasso_fit, "Lasso")/
viz_class_eval(rand_fit, "Random forest")/
viz_class_eval(xg_fit, "XGBoost")
```




